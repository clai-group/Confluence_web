{
  "hash": "f87c56c0d72686286c2e3b83d9c64f99",
  "result": {
    "markdown": "---\ntitle: \"EHCE Freauency Trend Analysis\"\nauthor: \"Jingya Cheng\"\ndate: \"2024-01-03\"\ncategories: [code, analysis, trend]\n---\n\n\n# Extreme Heat/Cold Events Frequency Trend Analysis\n\n\n\n\n\n### Loading the base spatail data set including Counties and States boundaires\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource_dir <- \"./data/\"\nstates_file_path <- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo <- readRDS(states_file_path)[[1]]\ncounties_file_path <- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo <- readRDS(counties_file_path)[[1]]\nplot(counties_geo[1])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### Loading the aggregate extreme events data set\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_path <- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size <- file.info(dat_path)$size\ndat <- readRDS(dat_path)[[1]]\n```\n:::\n\n\n### Overall frequency analysis\n\n#### Complete yearly aggregated counts\n\nComplete the yearly frequency counts by assign 0 to that year when there's no extreme event records.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_table = dat %>%  st_drop_geometry()\n\n## Adding years with no event to the dataset \nlookup_table <- dat_table %>%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %>%\n  distinct() %>%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup <- function(dat_table, lookup_table, column) {\n  na_rows <- is.na(dat_table[[column]])\n  lookup_values <- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] <- lookup_values\n  return(dat_table)\n}\n\nyear_range <- data.frame(year_numerical = 2008:2022)\nunique_geoids <- unique(dat$GEOID)\nyear_geoid_combinations <- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\nevent_count_all <- dat_table %>%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%\n  summarize(event_count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n```\n:::\n\n```{.r .cell-code}\nevent_count_all <- merge(year_geoid_combinations, event_count_all, \n                         by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_all[\"event_count\"] <- lapply(event_count_all[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_all <- fill_na_with_lookup(event_count_all, lookup_table, \"NAME\")\nevent_count_all <- fill_na_with_lookup(event_count_all, lookup_table, \"STATE_NAME\")\n```\n:::\n\n\n#### Poisson regression\n\nFor each county, a poisson regression model is used to analyze the percentage changes by year.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoisson_all <- event_count_all %>%\n  group_by(GEOID, NAME, STATE_NAME) %>%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: algorithm did not converge\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: fitted rates numerically 0 occurred\n```\n:::\n\n```{.r .cell-code}\n# Calculating slopes, percentage changes, and evaluation metrics including goodness of fit and p-values\nslopes_all <- poisson_all %>%\n  rowwise() %>%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(>|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model),\n  ) %>%\n  ungroup() %>%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(slopes_all$p_value)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_all$percentage_change)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_all$aic)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n:::\n\n\n#### Map\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Merge with geometry data\n#slopes_cut = slopes_all %>% filter(p_value < 0.1)\ncounty_boundaries_catalog_all <- merge(counties_geo,\n          slopes_all %>% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %>% st_as_sf() \n\n# Frequency all map with grey for non-significant p-values\nggplot() +\n  geom_sf(data = county_boundaries_catalog_all,\n            aes(fill = percentage_change), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limits = c(-22,22)) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Frequency EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n### Extreme Heat Events\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevent_count_ehe <- dat_table %>%\n  filter(event_type == \"Extreme Heat Event\") %>%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%\n  summarize(event_count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n```\n:::\n\n```{.r .cell-code}\nevent_count_ehe <- merge(year_geoid_combinations, event_count_ehe, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ehe[\"event_count\"] <- lapply(event_count_ehe[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_ehe <- fill_na_with_lookup(event_count_ehe, lookup_table, \"NAME\")\nevent_count_ehe <- fill_na_with_lookup(event_count_ehe, lookup_table, \"STATE_NAME\")\n\n# Poisson Regression\npoisson_ehe <- event_count_ehe %>%\n  group_by(GEOID, NAME, STATE_NAME) %>%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: algorithm did not converge\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: glm.fit: fitted rates numerically 0 occurred\n```\n:::\n\n```{.r .cell-code}\nslopes_ehe_poi <- poisson_ehe %>%\n  rowwise() %>%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(>|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %>%\n  ungroup() %>%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(slopes_ehe_poi$p_value)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_ehe_poi$percentage_change)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_ehe_poi$aic)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n\n\n#### Map\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#slopes_ehe_cut = slopes_ehe_poi %>% filter(p_value < 0.05)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog <- merge(counties_geo,\n          slopes_ehe_poi %>% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %>% st_as_sf() \n\n# Frequency EHE map\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = percentage_change), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-42, 42)) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.1) +\n  labs(fill = \"Frequency EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Extreme Cold Events\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevent_count_ece <- dat_table %>%\n  filter(event_type == \"Extreme Cold Event\") %>%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%\n  summarize(event_count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n```\n:::\n\n```{.r .cell-code}\nevent_count_ece <- merge(year_geoid_combinations, event_count_ece, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ece[\"event_count\"] <- lapply(event_count_ece[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_ece <- fill_na_with_lookup(event_count_ece, lookup_table, \"NAME\")\nevent_count_ece <- fill_na_with_lookup(event_count_ece, lookup_table, \"STATE_NAME\")\n\n# Poisson Regression\npoisson_ece <- event_count_ece %>%\n  group_by(GEOID, NAME, STATE_NAME) %>%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n\nslopes_ece_poi <- poisson_ece %>%\n  rowwise() %>%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(>|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %>%\n  ungroup() %>%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(slopes_ece_poi$p_value)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_ece_poi$percentage_change)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(slopes_ece_poi$aic)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n:::\n\n\n#### Map\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#slopes_ece_cut = slopes_ece_poi %>% filter(p_value < 0.05)\n# Merge with geometry data\ncounty_boundaris_ece_catalog <- merge(counties_geo,\n          slopes_ece_poi %>% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %>% st_as_sf() \n\n# Frequency ECE map\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = percentage_change), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-60, 60)) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Frequency ECE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
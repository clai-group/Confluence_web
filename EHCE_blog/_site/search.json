[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Confluence Projects",
    "section": "",
    "text": "Confluence noun\n:the flowing together of two or more streams\n\"Confluence.\" Merriam-Webster.com Dictionary, Merriam-Webster, https://www.merriam-webster.com/dictionary/confluence. Accessed 19 Apr. 2022.\n\nDescription: Aerial view of ’Ksan at Skeena-Bulkley confluence Source: Ksan at Skeena/Bulkley confluence\nClimate change is a grand challenge for life on Earth and will likely have devastating impacts on future generations. Regardless of whether our mitigation efforts are successful or not, varying degrees of climate impact are inevitable on different human populations. This is highly important due to a changing population that constantly shifts who is vulnerable and to what degree. \nIn the confluence project, we aim to focus on the transforming/unfolding impacts of climate change on vulnerable populations that can change in proportion and scale/magnitude due to other influential factors such as aging and diseases. \nWe study the confluence of environmental and demographic changes on the health outcomes for individuals and groups of people so that the outcomes can be translated into meaningful and actionable insight for ameliorating climate impacts on vulnerable populations.\n\nPosts\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nInteractive map — observation\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntrend\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2024\n\n\nJingya Cheng\n\n\n\n\n\n\n  \n\n\n\n\nInteractive map — Trends\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntrend\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2024\n\n\nJingya Cheng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "EHCE Freauency Trend Analysis",
    "section": "",
    "text": "Extreme Heat/Cold Events Frequency Trend Analysis\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\nplot(counties_geo[1])\n\n\n\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nOverall frequency analysis\n\nComplete yearly aggregated counts\nComplete the yearly frequency counts by assign 0 to that year when there’s no extreme event records.\n\ndat_table = dat %&gt;%  st_drop_geometry()\n\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\n\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\nevent_count_all &lt;- dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\nevent_count_all &lt;- merge(year_geoid_combinations, event_count_all, \n                         by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_all[\"event_count\"] &lt;- lapply(event_count_all[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_all &lt;- fill_na_with_lookup(event_count_all, lookup_table, \"NAME\")\nevent_count_all &lt;- fill_na_with_lookup(event_count_all, lookup_table, \"STATE_NAME\")\n\n\n\nPoisson regression\nFor each county, a poisson regression model is used to analyze the percentage changes by year.\n\npoisson_all &lt;- event_count_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n\nWarning: glm.fit: algorithm did not converge\n\n\nWarning: glm.fit: fitted rates numerically 0 occurred\n\n# Calculating slopes, percentage changes, and evaluation metrics including goodness of fit and p-values\nslopes_all &lt;- poisson_all %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n\nsummary(slopes_all)\n\n     GEOID          NAME            STATE_NAME            slope         \n 01069  :   1   Length:3108        Length:3108        Min.   :-0.16471  \n 01023  :   1   Class :character   Class :character   1st Qu.:-0.01133  \n 01005  :   1   Mode  :character   Mode  :character   Median : 0.01793  \n 01107  :   1                                         Mean   : 0.02268  \n 01033  :   1                                         3rd Qu.: 0.04379  \n 04012  :   1                                         Max.   :21.17677  \n (Other):3102                                                           \n percentage_change       p_value         residual_deviance  df_residual\n Min.   :-1.500e+01   Min.   :0.000000   Min.   :  0.00    Min.   :13  \n 1st Qu.:-1.000e+00   1st Qu.:0.004536   1st Qu.: 33.24    1st Qu.:13  \n Median : 2.000e+00   Median :0.087509   Median : 48.24    Median :13  \n Mean   : 5.064e+07   Mean   :0.238156   Mean   : 53.87    Mean   :13  \n 3rd Qu.: 4.000e+00   3rd Qu.:0.418585   3rd Qu.: 67.39    3rd Qu.:13  \n Max.   : 1.574e+11   Max.   :1.000000   Max.   :186.55    Max.   :13  \n                                                                       \n deviance_ratio     dispersion          aic        \n Min.   : 0.000   Min.   : 0.000   Min.   :  6.00  \n 1st Qu.: 2.557   1st Qu.: 2.414   1st Qu.: 96.18  \n Median : 3.711   Median : 3.522   Median :110.29  \n Mean   : 4.144   Mean   : 4.143   Mean   :116.36  \n 3rd Qu.: 5.184   3rd Qu.: 5.086   3rd Qu.:129.68  \n Max.   :14.350   Max.   :21.859   Max.   :252.52  \n                                                   \n\n\n\nhist(slopes_all$p_value)\n\n\n\nhist(slopes_all$percentage_change)\n\n\n\n\n\n\nMap\n\n# Merge with geometry data\nslopes_cut = slopes_all %&gt;% filter(p_value &lt; 0.05)\ncounty_boundaries_catalog_all &lt;- merge(counties_geo,\n          slopes_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency all map with grey for non-significant p-values\nggplot() +\n  geom_sf(data = county_boundaries_catalog_all,\n            aes(fill = percentage_change),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-40, 40),\n                       breaks = c( -40, -20, 0, 20, 40)) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Frequency EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nExtreme Heat Events\n\nevent_count_ehe &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Heat Event\") %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\nevent_count_ehe &lt;- merge(year_geoid_combinations, event_count_ehe, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ehe[\"event_count\"] &lt;- lapply(event_count_ehe[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_ehe &lt;- fill_na_with_lookup(event_count_ehe, lookup_table, \"NAME\")\nevent_count_ehe &lt;- fill_na_with_lookup(event_count_ehe, lookup_table, \"STATE_NAME\")\n\n# Poisson Regression\npoisson_ehe &lt;- event_count_ehe %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n\nWarning: glm.fit: algorithm did not converge\n\n\nWarning: glm.fit: fitted rates numerically 0 occurred\n\nslopes_ehe_poi &lt;- poisson_ehe %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n\n\nMap\n\nslopes_ehe_cut = slopes_ehe_poi %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog &lt;- merge(counties_geo,\n          slopes_ehe_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency EHE map\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = percentage_change),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-40, 40),\n                       breaks = c( -40, -20, 0, 20, 40)) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Frequency EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nExtreme Cold Events\n\nevent_count_ece &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Cold Event\") %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\nevent_count_ece &lt;- merge(year_geoid_combinations, event_count_ece, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ece[\"event_count\"] &lt;- lapply(event_count_ece[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\n\nevent_count_ece &lt;- fill_na_with_lookup(event_count_ece, lookup_table, \"NAME\")\nevent_count_ece &lt;- fill_na_with_lookup(event_count_ece, lookup_table, \"STATE_NAME\")\n\n# Poisson Regression\npoisson_ece &lt;- event_count_ece %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n\nslopes_ece_poi &lt;- poisson_ece %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n\n\nMap\n\nslopes_ece_cut = slopes_ece_poi %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ece_catalog &lt;- merge(counties_geo,\n          slopes_ece_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency ECE map\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = percentage_change),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-40, 40),\n                       breaks = c( -40, -20, 0, 20, 40)) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Frequency ECE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "EHCE Intensity Trend Analysis",
    "section": "",
    "text": "Extreme Heat/Cold Events Intensity Trend Analysis\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nCalculating the average intensity with complete yearly intensity records\n\nOverall intensity\n\ndat_table = dat %&gt;%  st_drop_geometry()\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\n## Overall\ndat_table$abs_intensity = abs(dat_table$avg_intensity)\n\ncounty_yearly_intensity &lt;- dat_table %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_all &lt;- merge(year_geoid_combinations, county_yearly_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_all[\"mean_intensity\"] &lt;- lapply(dat_intensity_all[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\ndat_intensity_all &lt;- fill_na_with_lookup(dat_intensity_all, \n                                               lookup_table, \"NAME\")\ndat_intensity_all &lt;- fill_na_with_lookup(dat_intensity_all, \n                                               lookup_table, \"STATE_NAME\")\n\n#linear regression and calcualte percentage change\nlm_intensity_all &lt;- dat_intensity_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_all &lt;- lm_intensity_all %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"])\n\n\n\nMap\n\nslopes_cut = slopes_all %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          slopes_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = slope),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limit = c(-3, 3),breaks = c(-3, 0, 3)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Intensity\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Heat Events\n\ncounty_heat_intensity &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Heat Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_ehe &lt;- merge(year_geoid_combinations, county_heat_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_ehe[\"mean_intensity\"] &lt;- lapply(dat_intensity_ehe[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\n\ndat_intensity_ehe &lt;- fill_na_with_lookup(dat_intensity_ehe, lookup_table, \"NAME\")\ndat_intensity_ehe &lt;- fill_na_with_lookup(dat_intensity_ehe, lookup_table, \"STATE_NAME\")\n\n## Standardized linear regression\nlm_intensity_ehe &lt;- dat_intensity_ehe %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_ehe &lt;- lm_intensity_ehe %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"])\n\n\n\nMap\n\nslopes_ehe_cut = slopes_ehe %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog &lt;- merge(counties_geo,\n          slopes_ehe_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity EHE map\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = slope),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-3, 3),\n                       breaks = c(-3,  0, 3)) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Intensity EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Cold Events\n\ncounty_cold_intensity &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Cold Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_ece &lt;- merge(year_geoid_combinations, county_cold_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_ece[\"mean_intensity\"] &lt;- lapply(dat_intensity_ece[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\n\ndat_intensity_ece &lt;- fill_na_with_lookup(dat_intensity_ece, lookup_table, \"NAME\")\ndat_intensity_ece &lt;- fill_na_with_lookup(dat_intensity_ece, lookup_table, \"STATE_NAME\")\n\nlm_intensity_ece &lt;- dat_intensity_ece %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_ece &lt;- lm_intensity_ece %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"])\n\n\n\nMap\n\nslopes_ece_cut = slopes_ece %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ece_catalog &lt;- merge(counties_geo,\n          slopes_ece_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity ECE map\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = slope),\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-4, 4),\n                       breaks = c(-4, 0, 4)) +\n  geom_sf(data = states_geo, fill = NA, color = \"black\", size = 0.5) +\n  labs(fill = \"Intensity ECE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html#loading-the-base-spatail-data-set-including-counties-and-states-boundaires",
    "href": "posts/welcome/index.html#loading-the-base-spatail-data-set-including-counties-and-states-boundaires",
    "title": "EHCE Freauency Trend Analysis",
    "section": "",
    "text": "source_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\nplot(counties_geo[1])"
  },
  {
    "objectID": "posts/welcome/index.html#loading-the-aggregate-extreme-events-data-set",
    "href": "posts/welcome/index.html#loading-the-aggregate-extreme-events-data-set",
    "title": "EHCE Freauency Trend Analysis",
    "section": "",
    "text": "dat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]"
  },
  {
    "objectID": "index.html#confluence-noun",
    "href": "index.html#confluence-noun",
    "title": "Confluence Projects",
    "section": "Confluence noun",
    "text": "Confluence noun\nThe flowing together of two or more streams\n\"Confluence.\" Merriam-Webster.com Dictionary, Merriam-Webster, https://www.merriam-webster.com/dictionary/confluence. Accessed 19 Apr. 2022."
  },
  {
    "objectID": "posts/Intensity/index.html",
    "href": "posts/Intensity/index.html",
    "title": "EHCE Intensity Trend Analysis",
    "section": "",
    "text": "Extreme Heat/Cold Events Intensity Trend Analysis\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nCalculating the average intensity with complete yearly intensity records\n\nOverall intensity\n\ndat_table = dat %&gt;%  st_drop_geometry()\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\n## Overall\ndat_table$abs_intensity = abs(dat_table$avg_intensity)\n\ncounty_yearly_intensity &lt;- dat_table %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_all &lt;- merge(year_geoid_combinations, county_yearly_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_all[\"mean_intensity\"] &lt;- lapply(dat_intensity_all[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\ndat_intensity_all &lt;- fill_na_with_lookup(dat_intensity_all, \n                                               lookup_table, \"NAME\")\ndat_intensity_all &lt;- fill_na_with_lookup(dat_intensity_all, \n                                               lookup_table, \"STATE_NAME\")\n\n#linear regression and calcualte percentage change with standardized average intensity \nlm_intensity_all &lt;- dat_intensity_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_all &lt;- lm_intensity_all %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\n\nhist(slopes_all$p_value)\n\n\n\nhist(slopes_all$slope)\n\n\n\nhist(slopes_all$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_cut = slopes_all %&gt;% filter(!(p_value &gt; 0.5))\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          slopes_all %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = slope), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limits = c(-2.6, 2.6)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.01, alpha = 0.2) +\n  labs(fill = \"Intensity\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Heat Events\n\ncounty_heat_intensity &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Heat Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_ehe &lt;- merge(year_geoid_combinations, county_heat_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_ehe[\"mean_intensity\"] &lt;- lapply(dat_intensity_ehe[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\n\ndat_intensity_ehe &lt;- fill_na_with_lookup(dat_intensity_ehe, lookup_table, \"NAME\")\ndat_intensity_ehe &lt;- fill_na_with_lookup(dat_intensity_ehe, lookup_table, \"STATE_NAME\")\n\n## Standardized linear regression\nlm_intensity_ehe &lt;- dat_intensity_ehe %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_ehe &lt;- lm_intensity_ehe %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\n\nhist(slopes_ehe$p_value)\n\n\n\nhist(slopes_ehe$slope)\n\n\n\nhist(slopes_ehe$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_ehe_cut = slopes_ehe %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog &lt;- merge(counties_geo,\n          slopes_ehe %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity EHE map\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = slope),color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-2.5, 2.5)) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Intensity EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Cold Events\n\ncounty_cold_intensity &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Cold Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(mean_intensity = mean(abs_intensity))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_intensity_ece &lt;- merge(year_geoid_combinations, county_cold_intensity, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_intensity_ece[\"mean_intensity\"] &lt;- lapply(dat_intensity_ece[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\n\ndat_intensity_ece &lt;- fill_na_with_lookup(dat_intensity_ece, lookup_table, \"NAME\")\ndat_intensity_ece &lt;- fill_na_with_lookup(dat_intensity_ece, lookup_table, \"STATE_NAME\")\n\nlm_intensity_ece &lt;- dat_intensity_ece %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(mean_intensity ~ year_numerical, data = .))\n\nslopes_ece &lt;- lm_intensity_ece %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\n\nhist(slopes_ece$p_value)\n\n\n\nhist(slopes_ece$slope)\n\n\n\nhist(slopes_ece$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_ece_cut = slopes_ece %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ece_catalog &lt;- merge(counties_geo,\n          slopes_ece %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Intensity ECE map\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = slope), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", limit = c(-4, 4)) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Intensity ECE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/Frequency/index.html",
    "href": "posts/Frequency/index.html",
    "title": "EHCE Frequency Trend Analysis",
    "section": "",
    "text": "Extreme Heat/Cold Events Frequency Trend Analysis\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\n#plot(counties_geo[1])\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nOverall frequency analysis\n\nComplete yearly aggregated counts\nComplete the yearly frequency counts by assign 0 to that year when there’s no extreme event records.\n\ndat_table = dat %&gt;%  st_drop_geometry()\ndat_table$total_area_sq_mile = dat_table$total_area/2590000\n\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  dplyr::select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\n\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\nevent_count_all &lt;- dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\nevent_count_all &lt;- merge(year_geoid_combinations, event_count_all, \n                         by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_all[\"event_count\"] &lt;- lapply(event_count_all[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\nevent_count_all &lt;- fill_na_with_lookup(event_count_all, lookup_table, \"NAME\")\nevent_count_all &lt;- fill_na_with_lookup(event_count_all, lookup_table, \"STATE_NAME\")\n\n# Merge with average total area sq miles summary \navg_total_area &lt;- dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))\n\n`summarise()` has grouped output by 'GEOID', 'NAME'. You can override using the\n`.groups` argument.\n\nevent_count_all = merge(event_count_all, avg_total_area, \n                         by = c(\"GEOID\", \"NAME\", \"STATE_NAME\"), all = TRUE)\n\n\n\nAverage counts by county\n\n# Yearly average counts per area\navg_dat_by_year = event_count_all %&gt;%\n  mutate(avg_counts = event_count/avg_total_area_sq_mile) %&gt;% \n  distinct()\n\navg_dat_by_year %&gt;% group_by(STATE_NAME) %&gt;% \n  ggplot(aes(x = avg_counts, y = STATE_NAME), data = .) +\n  stat_density_ridges(quantile_lines = TRUE, quantiles = 0.5)+ theme_minimal() + xlim(c(0,0.075))\n\nPicking joint bandwidth of 0.0016\n\n\n\n\n# Overall average counts per area\navg_dat = dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  summarize(event_count = n(),\n            avg_total_area_sq_mile = mean(total_area_sq_mile))%&gt;%\n  mutate(avg_counts = event_count/avg_total_area_sq_mile) %&gt;% \n  distinct()\n\n`summarise()` has grouped output by 'GEOID', 'NAME'. You can override using the\n`.groups` argument.\n\nggplot(avg_dat, aes(x = avg_counts)) + \n  geom_histogram(aes(y = ..density..),\n                 colour = 1, fill = \"white\") +\n  geom_density(lwd = 1, colour = 4,\n               fill = 4, alpha = 0.25) +\n  geom_vline(aes(xintercept=mean(avg_counts, na.rm=T)),  \n               color=\"red\", linetype=\"dashed\", size=1) + xlim(c(0,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\navg_dat = avg_dat %&gt;%\n  mutate(avg_counts_cat = case_when(\n    avg_counts &lt; 0.14 ~ \"&lt;0.14\",\n    avg_counts &gt;=0.14 & avg_counts &lt;= 0.26 ~ \"0.14-0.26\",\n    avg_counts &gt;0.26 & avg_counts &lt;= 1 ~ \"0.26-1\", \n    TRUE ~ \"&gt;1\"\n  )) %&gt;%\n  mutate(avg_counts_cat = factor(avg_counts_cat, \n                                        levels = c('&lt;0.14', \"0.14-0.26\", '0.26-1',\n                                                   '&gt;1')))\n\ncounty_boundaries_catalog_all_counts &lt;- merge(counties_geo,\n          avg_dat %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \npalette &lt;- rev(brewer.pal(4, \"RdYlBu\"))\n# Frequency all map with grey for non-significant p-values\nggplot() +\n  geom_sf(data = county_boundaries_catalog_all_counts,\n            aes(fill = avg_counts_cat), color = NA,\n            lwd = .1) + \n  scale_fill_manual(values = palette) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Average Number of Extreme Events (2008-2022)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nPoisson regression\nFor each county, a poisson regression model is used to analyze the percentage changes by year.\n\n#poisson_all_area_freq &lt;- event_count_all %&gt;%\n#  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n#  do(model = glm(event_count ~ year_numerical + \n#                   avg_total_area_sq_mile, family = poisson(), data = .))\n\npoisson_all_area_freq &lt;- event_count_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = MASS::glm.nb(event_count ~ year_numerical + \n                            offset(log(avg_total_area_sq_mile)), data = .))\n\n# Calculating slopes, percentage changes, and evaluation metrics including goodness of fit and p-values\nslopes_all_area_adj &lt;- poisson_all_area_freq %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model),bic = BIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic,bic)\n\nslopes_all_area_adj = slopes_all_area_adj %&gt;%\n  mutate(percentage_change_cat = case_when(\n    percentage_change &lt; -10 ~ \"&lt;-10%\",\n    percentage_change &gt;=-10 & percentage_change&lt;= -5 ~ \"-10 - -5%\",\n    percentage_change &gt;-5 & percentage_change&lt;= -1 ~ \"-5 - -1%\",\n    percentage_change &gt;-1 & percentage_change&lt;= 0 ~ \"-1-0%\",\n    percentage_change &gt;0 & percentage_change&lt;= 1 ~ \"0-1%\",\n    percentage_change &gt;1 & percentage_change &lt;= 5 ~ \"1-5%\",\n    percentage_change &gt;5 & percentage_change &lt;= 10 ~ \"5-10%\", \n    TRUE ~ \"&gt;10%\"\n  )) %&gt;%\n  mutate(percentage_change_cat = factor(percentage_change_cat, \n                                        levels = c(\"&lt;-10%\",\"-10 - -5%\",\"-5 - -1%\",\n                                                   \"-1-0%\",\"0-1%\",\n                                                   \"1-5%\", \"5-10%\", \"&gt;10%\")))\n\n#alabama = slopes_all_area_freq %&gt;% filter(STATE_NAME == \"Alabama\")\n#anova_result &lt;- aov(slope ~ NAME, data = alabama)\n#summary(anova_result)\n#summary(anova_result)[[1]][[\"Pr(&gt;F)\"]][1]\n\n#anova_results &lt;- list()\n#for (state_name in unique(slopes_all_area_freq$STATE_NAME)) {\n#  state_data &lt;- slopes_all_area_freq[slopes_all_area_freq$STATE_NAME == state_name, ]\n#  if (length(unique(state_data$NAME)) &gt; 1) {\n#      anova_results[[state_name]] &lt;- summary(aov(slope ~ NAME, data = state_data))\n#  }\n#}\n\n\n\nModel Selection\n\nNB_regression = event_count_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = MASS::glm.nb(event_count ~ year_numerical + \n                            offset(log(avg_total_area_sq_mile)), data = .))\n\nslopes_nb &lt;- NB_regression %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,\n    aic = AIC(model),\n    bic = BIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change, p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic, bic)\n\nmodel_comparison_table1 &lt;- event_count_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  summarize(\n    NB_Model_AIC = AIC(NB_regression$model[[1]]),\n    Poisson_Model_AIC = AIC(poisson_all_area_freq$model[[1]]),\n    Preferred_Model_AIC = ifelse(NB_Model_AIC &lt; Poisson_Model_AIC, \"Negative Binomial\", \"Poisson\"),\n    NB_Model_BIC = BIC(NB_regression$model[[1]]),\n    Poisson_Model_BIC = BIC(poisson_all_area_freq$model[[1]]),\n    Preferred_Model_BIC = ifelse(NB_Model_BIC &lt; Poisson_Model_BIC, \"Negative Binomial\", \"Poisson\"),\n    NB_Model_RD = NB_regression$model[[1]]$deviance,\n    Poisson_Model_RD = poisson_all_area_freq$model[[1]]$deviance,\n    Preferred_Model_RD = ifelse(NB_Model_RD &lt; Poisson_Model_RD, \"Negative Binomial\", \"Poisson\")\n  )\n\n`summarise()` has grouped output by 'GEOID', 'NAME'. You can override using the\n`.groups` argument.\n\n\n\n#hist(slopes_all_area_freq$p_value)\n#hist(slopes_all_area_freq$percentage_change)\n#hist(slopes_all_area_freq$aic)\n#hist(slopes_all_area_freq$pseudo_r_squared)\n\n\n\nMap\n\n# Merge with geometry data\nslopes_all_cut = slopes_all_area_adj %&gt;% filter(abs(percentage_change) &lt; 45)\ncounty_boundaries_catalog_all &lt;- merge(counties_geo,\n          slopes_all_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency all map with grey for non-significant p-values\n#ggplot() +\n#  geom_sf(data = county_boundaries_catalog_all,\n#            aes(fill = percentage_change), color = NA,\n#            lwd = .1) + \n#  scale_fill_distiller(palette = \"RdBu\", limits = c(-17,17)) +\n#  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n#  labs(fill = \"Frequency (Area adjusted)\") +\n#  theme_void() + \n#  theme(legend.position = \"bottom\")\n\n#heat_colors &lt;- c(\"&lt;1%\" = \"lightblue\", \"1-5%\" = \"yellow\", \"5-10%\" = \"orange\", \"&gt;10%\" = \"red\")\npalette &lt;- rev(brewer.pal(8, \"RdBu\"))\nggplot() +\n  geom_sf(data = county_boundaries_catalog_all,\n            aes(fill = percentage_change_cat), color = NA,\n            lwd = .1) + \n  scale_fill_manual(values = palette, na.translate = F) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Percentage Change in Frequency (Area adjusted)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nPrediction\n\n#prediction_data &lt;- expand.grid(\n#  year_numerical = c(2025, 2030),\n#  avg_impacted_area_hectare = event_count_all$avg_impacted_area_hectare\n#)\n\n#predictions &lt;- poisson_all_area_freq %&gt;%\n#  mutate(\n#    predictions = list(\n#      apply(prediction_data, 1, function(new_data) {\n#        new_data &lt;- as.data.frame(t(new_data))\n#        pred &lt;- predict(model, newdata = new_data, type = \"response\", se.fit = TRUE)\n#        data.frame(\n#          prediction = pred$fit,\n#          lower_95 = pred$fit - 1.96 * pred$se.fit,\n#          upper_95 = pred$fit + 1.96 * pred$se.fit\n#        )\n#      })\n#    )\n#  ) %&gt;%\n#  select(GEOID, NAME, STATE_NAME, predictions)\n\n\n\n\nExtreme Heat Events\n\nevent_count_ehe &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Heat Event\") %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\nevent_count_ehe &lt;- merge(year_geoid_combinations, event_count_ehe, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ehe[\"event_count\"] &lt;- lapply(event_count_ehe[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\nevent_count_ehe &lt;- fill_na_with_lookup(event_count_ehe, lookup_table, \"NAME\")\nevent_count_ehe &lt;- fill_na_with_lookup(event_count_ehe, lookup_table, \"STATE_NAME\")\n\n# Merge with average total area sq miles summary \navg_total_area_ehe &lt;- dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))\nevent_count_ehe = merge(event_count_ehe, avg_total_area_ehe, \n                         by = c(\"GEOID\", \"NAME\", \"STATE_NAME\"), all = TRUE)\n\n# Poisson Regression\npoisson_ehe_area_adj &lt;- event_count_ehe %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = MASS::glm.nb(event_count ~ year_numerical + \n                            offset(log(avg_total_area_sq_mile)), data = .))\n\nslopes_ehe_poi_area_adj &lt;- poisson_ehe_area_adj %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model), bic = BIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic,bic)\n\nslopes_ehe_poi_area_adj = slopes_ehe_poi_area_adj %&gt;%\n  mutate(percentage_change_cat = case_when(\n    percentage_change &lt; -10 ~ \"&lt;-10%\",\n    percentage_change &gt;=-10 & percentage_change&lt;= -5 ~ \"-10 - -5%\",\n    percentage_change &gt;-5 & percentage_change&lt;= -1 ~ \"-5 - -1%\",\n    percentage_change &gt;-1 & percentage_change&lt;= 0 ~ \"-1-0%\",\n    percentage_change &gt;0 & percentage_change&lt;= 1 ~ \"0-1%\",\n    percentage_change &gt;1 & percentage_change &lt;= 5 ~ \"1-5%\",\n    percentage_change &gt;5 & percentage_change &lt;= 10 ~ \"5-10%\", \n    TRUE ~ \"&gt;10%\"\n  )) %&gt;%\n  mutate(percentage_change_cat = factor(percentage_change_cat, \n                                        levels = c(\"&lt;-10%\",\"-10 - -5%\",\"-5 - -1%\",\n                                                   \"-1-0%\",\"0-1%\",\n                                                   \"1-5%\", \"5-10%\", \"&gt;10%\")))\n\n\nhist(slopes_ehe_poi_area_adj$p_value)\n\n\n\nhist(slopes_ehe_poi_area_adj$percentage_change)\n\n\n\nhist(slopes_ehe_poi_area_adj$aic)\n\n\n\n\n\nAverage Counts by County\n\navg_counts_county_ehe = event_count_ehe %&gt;% \n  group_by(GEOID, NAME, STATE_NAME) %&gt;% \n  summarise(county_avg_count = mean(event_count))\n\n`summarise()` has grouped output by 'GEOID', 'NAME'. You can override using the\n`.groups` argument.\n\ncounty_boundaries_catalog_ehe_counts &lt;- merge(counties_geo,\n          avg_counts_county_ehe %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency all map with grey for non-significant p-values\nggplot() +\n  geom_sf(data = county_boundaries_catalog_ehe_counts,\n            aes(fill = county_avg_count), color = NA,\n            lwd = .1) + \n  scale_fill_viridis_c(option = \"B\", direction = -1) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Average Number of Extreme Heat Events (2008-2022)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nMap\n\nslopes_ehe_cut = slopes_ehe_poi_area_adj %&gt;% filter(abs(percentage_change) &lt; 45)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog &lt;- merge(counties_geo,\n          slopes_ehe_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency EHE map\n#ggplot() +\n#  geom_sf(data = county_boundaris_ehe_catalog,\n#            aes(fill = percentage_change), color = NA,\n#            lwd = .1) + \n#  scale_fill_distiller(palette = \"RdBu\", limit = c(-42.5, 42.5)) +\n#  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.1) +\n#  labs(fill = \"Frequency EHE (Adjusted by Area)\") +\n#  theme_void() + \n#  theme(legend.position = \"bottom\")\n\n#heat_colors &lt;- c(\"&lt;1%\" = \"lightblue\", \"1-5%\" = \"yellow\", \"5-10%\" = \"orange\", \"&gt;10%\" = \"red\")\npalette &lt;- rev(brewer.pal(8, \"RdBu\"))\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = percentage_change_cat), color = NA,\n            lwd = .1) + \n  scale_fill_manual(values = palette, na.translate = F) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Percentage Change in Frequency EHE (Area adjusted)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nExtreme Cold Events\n\nevent_count_ece &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Cold Event\") %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(event_count = n())\n\nevent_count_ece &lt;- merge(year_geoid_combinations, event_count_ece, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nevent_count_ece[\"event_count\"] &lt;- lapply(event_count_ece[\"event_count\"], function(x) ifelse(is.na(x), 0, x))\nevent_count_ece &lt;- fill_na_with_lookup(event_count_ece, lookup_table, \"NAME\")\nevent_count_ece &lt;- fill_na_with_lookup(event_count_ece, lookup_table, \"STATE_NAME\")\n\n# Merge with average total area sq miles summary \navg_total_area_ece &lt;- dat_table %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))\nevent_count_ece = merge(event_count_ece, avg_total_area_ece, \n                         by = c(\"GEOID\", \"NAME\", \"STATE_NAME\"), all = TRUE)\n\n# NB Regression\nslopes_ece_poi_area_adj &lt;- event_count_ece %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do({\n    # Fit the Negative Binomial model\n    tryCatch({\n      model = MASS::glm.nb(event_count ~ year_numerical + \n                            offset(log(avg_total_area_sq_mile)), data = .)\n      coef_model = coef(model)[\"year_numerical\"]\n      percentage_change = (exp(coef_model) - 1) * 100\n      p_values = summary(model)$coefficients[\"year_numerical\", \"Pr(&gt;|z|)\"]\n      aic_value = AIC(model)\n      bic_value = BIC(model)\n\n      data.frame(coef = coef_model, percentage_change, p_value = p_values, \n                 AIC = aic_value, BIC = bic_value)\n    }, error = function(e) {\n      # Return NA in case of an error\n      data.frame(coef = NA, percentage_change = NA, p_value = NA, \n                 AIC = NA, BIC = NA)\n    })\n  })\n#poisson_ece_area_adj &lt;- event_count_ece %&gt;%\n#  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n#  do(model = glm(event_count ~ year_numerical + \n#                   offset(log(avg_total_area_sq_mile)), family = quasipoisson, data = .))\n\nslopes_ece_poi_area_adj = slopes_ece_poi_area_adj %&gt;%\n  mutate(percentage_change_cat = case_when(\n    percentage_change &lt; -10 ~ \"&lt;-10%\",\n    percentage_change &gt;=-10 & percentage_change&lt;= -5 ~ \"-10 - -5%\",\n    percentage_change &gt;-5 & percentage_change&lt;= -1 ~ \"-5 - -1%\",\n    percentage_change &gt;-1 & percentage_change&lt;= 0 ~ \"-1-0%\",\n    percentage_change &gt;0 & percentage_change&lt;= 1 ~ \"0-1%\",\n    percentage_change &gt;1 & percentage_change &lt;= 5 ~ \"1-5%\",\n    percentage_change &gt;5 & percentage_change &lt;= 10 ~ \"5-10%\", \n    percentage_change &gt; 10 ~ \"&gt;10%\"\n  )) %&gt;%\n  mutate(percentage_change_cat = factor(percentage_change_cat, \n                                        levels = c(\"&lt;-10%\",\"-10 - -5%\",\"-5 - -1%\",\n                                                   \"-1-0%\",\"0-1%\",\n                                                   \"1-5%\", \"5-10%\", \"&gt;10%\")))\n\n\n#hist(slopes_ece_poi$p_value)\n#hist(slopes_ece_poi$percentage_change)\n#hist(slopes_ece_poi$aic)\n\n\nAverage counts by county\n\navg_counts_county_ece = event_count_ece %&gt;% \n  group_by(GEOID, NAME, STATE_NAME) %&gt;% \n  summarise(county_avg_count = mean(event_count))\n\n`summarise()` has grouped output by 'GEOID', 'NAME'. You can override using the\n`.groups` argument.\n\ncounty_boundaries_catalog_ece_counts &lt;- merge(counties_geo,\n          avg_counts_county_ece %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency all map with grey for non-significant p-values\nggplot() +\n  geom_sf(data = county_boundaries_catalog_ece_counts,\n            aes(fill = county_avg_count), color = NA,\n            lwd = .1) + \n  scale_fill_viridis_c(option = \"D\", direction = -1) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Average Number of Extreme Cold Events (2008-2022)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nMap\n\nslopes_ece_cut = slopes_ece_poi_area_adj %&gt;% filter(abs(percentage_change) &lt; 45)\n# Merge with geometry data\ncounty_boundaris_ece_catalog &lt;- merge(counties_geo,\n          slopes_ece_cut %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n\n# Frequency ECE map\n#ggplot() +\n#  geom_sf(data = county_boundaris_ece_catalog,\n#            aes(fill = percentage_change), color = NA,\n#            lwd = .1) + \n#  scale_fill_distiller(palette = \"RdBu\", limit = c(-27, 27)) +\n#  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n#  labs(fill = \"Frequency ECE (Adjusted by area)\") +\n#  theme_void() + \n#  theme(legend.position = \"bottom\")\n\n#heat_colors &lt;- c(\"&lt;1%\" = \"lightblue\", \"1-5%\" = \"yellow\", \"5-10%\" = \"orange\", \"&gt;10%\" = \"red\")\npalette &lt;- rev(brewer.pal(8, \"RdBu\"))\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = percentage_change_cat), color = NA,\n            lwd = .1) + \n  scale_fill_manual(values = palette, na.translate = F) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Percentage Change in Frequency ECE (Area adjusted)\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nState Level Analysis\n\nstate_ehe_dat = event_count_ehe %&gt;% \n  dplyr::select(year_numerical, STATE_NAME, event_count) \n\npoi_state_ehe &lt;- state_ehe_dat %&gt;%\n  group_by(STATE_NAME) %&gt;%\n  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))\n\nslopes_state_ehe &lt;- poi_state_ehe %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    slope = coef(model)[[\"year_numerical\"]],\n    percentage_change = (exp(slope) - 1) * 100,\n    p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|z|)\"],\n    residual_deviance = deviance(model),\n    df_residual = df.residual(model),\n    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom\n    dispersion = sum(residuals(model, type = \"pearson\")^2) / df_residual,  # Dispersion parameter\n    aic = AIC(model)\n  ) %&gt;%\n  ungroup() %&gt;%\n  dplyr::select(STATE_NAME, slope, percentage_change,p_value,\n         residual_deviance, df_residual, \n         deviance_ratio, dispersion, aic)\n\n\nMap\n\n# Merge with geometry data\nstate_boundaris_ehe_catalog &lt;- merge(states_geo,\n          slopes_state_ehe %&gt;% st_drop_geometry(),\n          by.x=\"STATE_NAME\",\n          by.y=\"STATE_NAME\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Area ECE map\nggplot() +\n  geom_sf(data = state_boundaris_ehe_catalog,\n            aes(fill = percentage_change), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-10.7, 10.7)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"State Frequency EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/Area/index.html",
    "href": "posts/Area/index.html",
    "title": "EHCE Area Trend Analysis",
    "section": "",
    "text": "Extreme Heat/Cold Events Area Trend Analysis\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nCalculating the average area with complete yearly area records\n\nOverall area\n\ndat_table = dat %&gt;%  st_drop_geometry()\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\n## Overall\ncounty_yearly_area_hectare &lt;- dat_table %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(avg_impacted_to_total_ratio = mean(impacted_to_total_ratio))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_area_all &lt;- merge(year_geoid_combinations, county_yearly_area_hectare, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_area_all[\"avg_impacted_to_total_ratio\"] &lt;- lapply(dat_area_all[\"avg_impacted_to_total_ratio\"], function(x) ifelse(is.na(x), 0, x))\ndat_area_all &lt;- fill_na_with_lookup(dat_area_all, \n                                               lookup_table, \"NAME\")\ndat_area_all &lt;- fill_na_with_lookup(dat_area_all, \n                                               lookup_table, \"STATE_NAME\")\n\n#linear regression and calcualte percentage change\nlm_area_all &lt;- dat_area_all %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(avg_impacted_to_total_ratio~ year_numerical, data = .))\n\nslopes_all &lt;- lm_area_all %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\nWarning: There were 3 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `p_value = summary(model)$coefficients[\"year_numerical\",\n  \"Pr(&gt;|t|)\"]`.\nℹ In row 2810.\nCaused by warning in `summary.lm()`:\n! essentially perfect fit: summary may be unreliable\nℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\n\n\nhist(slopes_all$p_value)\n\n\n\nhist(slopes_all$slope)\n\n\n\nhist(slopes_all$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_cut = slopes_all %&gt;% filter(!(p_value &gt; 0.5))\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          slopes_all %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# area all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = slope), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-0.065, 0.065),\n                       breaks = c(-0.05, 0, 0.05),\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.01, alpha = 0.2) +\n  labs(fill = \"Area\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Heat Events\n\ncounty_ehe_area_hectare &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Heat Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(avg_impacted_to_total_ratio = mean(impacted_to_total_ratio))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_area_ehe &lt;- merge(year_geoid_combinations, county_ehe_area_hectare, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_area_ehe[\"avg_impacted_to_total_ratio\"] &lt;- lapply(dat_area_ehe[\"avg_impacted_to_total_ratio\"], function(x) ifelse(is.na(x), 0, x))\ndat_area_ehe &lt;- fill_na_with_lookup(dat_area_ehe, \n                                               lookup_table, \"NAME\")\ndat_area_ehe &lt;- fill_na_with_lookup(dat_area_ehe, \n                                               lookup_table, \"STATE_NAME\")\n\n#linear regression and calcualte percentage change\nlm_area_ehe &lt;- dat_area_ehe %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(avg_impacted_to_total_ratio ~ year_numerical, data = .))\n\nslopes_ehe &lt;- lm_area_ehe %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\n\nhist(slopes_ehe$p_value)\n\n\n\nhist(slopes_ehe$slope)\n\n\n\nhist(slopes_ehe$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_ehe_cut = slopes_ehe %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ehe_catalog &lt;- merge(counties_geo,\n          slopes_ehe %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Area EHE map\nggplot() +\n  geom_sf(data = county_boundaris_ehe_catalog,\n            aes(fill = slope),color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-0.085, 0.085)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Area EHE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nExtreme Cold Events\n\ncounty_ece_area_hectare &lt;- dat_table %&gt;%\n  filter(event_type == \"Extreme Cold Event\") %&gt;%\n  group_by(GEOID,NAME, STATE_NAME, year_numerical) %&gt;%\n  summarize(avg_impacted_to_total_ratio = mean(impacted_to_total_ratio))\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\ndat_area_ece &lt;- merge(year_geoid_combinations, county_ece_area_hectare, by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\ndat_area_ece[\"avg_impacted_to_total_ratio\"] &lt;- lapply(dat_area_ece[\"avg_impacted_to_total_ratio\"], function(x) ifelse(is.na(x), 0, x))\ndat_area_ece &lt;- fill_na_with_lookup(dat_area_ece, \n                                               lookup_table, \"NAME\")\ndat_area_ece &lt;- fill_na_with_lookup(dat_area_ece, \n                                               lookup_table, \"STATE_NAME\")\n\n#linear regression and calcualte percentage change\nlm_area_ece &lt;- dat_area_ece %&gt;%\n  group_by(GEOID, NAME, STATE_NAME) %&gt;%\n  do(model = lm(avg_impacted_to_total_ratio ~ year_numerical, data = .))\n\nslopes_ece &lt;- lm_area_ece %&gt;%\n  rowwise() %&gt;%\n  mutate(slope = coef(model)[[\"year_numerical\"]],\n         p_value = summary(model)$coefficients[\"year_numerical\",\"Pr(&gt;|t|)\"],\n         r_squared = glance(model)$r.squared)\n\n\nhist(slopes_ece$p_value)\n\n\n\nhist(slopes_ece$slope)\n\n\n\nhist(slopes_ece$r_squared)\n\n\n\n\n\n\nMap\n\n#slopes_ece_cut = slopes_ece %&gt;% filter(p_value &lt; 0.05)\n# Merge with geometry data\ncounty_boundaris_ece_catalog &lt;- merge(counties_geo,\n          slopes_ece %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# Area ECE map\nggplot() +\n  geom_sf(data = county_boundaris_ece_catalog,\n            aes(fill = slope), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-0.071, 0.071)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.5) +\n  labs(fill = \"Area ECE\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/Season/index.html",
    "href": "posts/Season/index.html",
    "title": "EHE Season Trend Analysis",
    "section": "",
    "text": "Season Analysis for Extreme Heat Events\n\nLoading the base spatail data set including Counties and States boundaires\n\nsource_dir &lt;- \"./data/\"\nstates_file_path &lt;- file.path(source_dir,\n                              \"us49_states_geo_tigris.rds\")\nstates_geo &lt;- readRDS(states_file_path)[[1]]\ncounties_file_path &lt;- file.path(source_dir,\n                                \"us49_counties_geo_tigris.rds\")\ncounties_geo &lt;- readRDS(counties_file_path)[[1]]\n\n\n\nLoading the aggregate extreme events data set\n\ndat_path &lt;- file.path(source_dir,\n                      \"Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds\")\nfile_size &lt;- file.info(dat_path)$size\ndat &lt;- readRDS(dat_path)[[1]]\n\n\n\nCreate seasonal summary by county\n\noptions(scipen=999)\ndat_table = dat %&gt;%  st_drop_geometry()\ndat_ehe_season = dat_table %&gt;% filter(event_type == 'Extreme Heat Event') %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME, event_date, event_type, avg_intensity, year_numerical, \n         month_numerical, day_numerical)\ndat_ehe_season$event_date = as.Date(dat_ehe_season$event_date)\n## Adding years with no event to the dataset \nlookup_table &lt;- dat_table %&gt;%\n  select(GEOID, NAME, STUSPS, STATE_NAME) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))\n\nfill_na_with_lookup &lt;- function(dat_table, lookup_table, column) {\n  na_rows &lt;- is.na(dat_table[[column]])\n  lookup_values &lt;- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]\n  dat_table[[column]][na_rows] &lt;- lookup_values\n  return(dat_table)\n}\nyear_range &lt;- data.frame(year_numerical = 2008:2022)\nunique_geoids &lt;- unique(dat$GEOID)\nyear_geoid_combinations &lt;- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)\n\nseason_table &lt;- dat_ehe_season %&gt;%\n  group_by(GEOID, NAME, STATE_NAME, year_numerical) %&gt;%\n  summarise(\n    mean_intensity = mean(avg_intensity),\n    first_event = min(day_numerical),\n    last_event = max(day_numerical),\n    duration = as.numeric(difftime(max(event_date), min(event_date), units = \"days\")) + 1\n  )\n\n`summarise()` has grouped output by 'GEOID', 'NAME', 'STATE_NAME'. You can\noverride using the `.groups` argument.\n\nseason_table &lt;- merge(year_geoid_combinations, \n                      season_table, \n                      by = c(\"year_numerical\", \"GEOID\"), all = TRUE)\nseason_table[\"mean_intensity\"] &lt;- lapply(season_table[\"mean_intensity\"], function(x) ifelse(is.na(x), 0, x))\nseason_table[\"first_event\"] &lt;- lapply(season_table[\"first_event\"], function(x) ifelse(is.na(x), 0, x))\nseason_table[\"last_event\"] &lt;- lapply(season_table[\"last_event\"], function(x) ifelse(is.na(x), 0, x))\nseason_table[\"duration\"] &lt;- lapply(season_table[\"duration\"], function(x) ifelse(is.na(x), 0, x))\nseason_table &lt;- fill_na_with_lookup(season_table, \n                                    lookup_table, \"NAME\")\nseason_table &lt;- fill_na_with_lookup(season_table,\n                                    lookup_table, \"STATE_NAME\")\n\n\n\nDuration Analysis\n\noptions(scipen=999)\nduration_analysis &lt;- season_table %&gt;%\n  group_by(GEOID, NAME) %&gt;%\n  do(tidy(lm(duration ~ year_numerical, data = .)))\nduration_analysis = duration_analysis %&gt;% filter(term != '(Intercept)')\n\n\nhist(duration_analysis$p.value)\n\n\n\n\n\nMap\n\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          duration_analysis %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# area all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = estimate), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-9, 9)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.01, alpha = 0.2) +\n  labs(fill = \"EHE Duration\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFirst Event Analysis\n\noptions(scipen=999)\nfirst_event_analysis &lt;- season_table %&gt;%\n  group_by(GEOID, NAME) %&gt;%\n  do(tidy(lm(first_event ~ year_numerical, data = .)))\nfirst_event_analysis = first_event_analysis %&gt;% filter(term != '(Intercept)')\n\n\nhist(first_event_analysis$p.value)\n\n\n\n\n\nMap\n\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          first_event_analysis %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# area all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = estimate), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-17.2, 17.2)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.01, alpha = 0.2) +\n  labs(fill = \"EHE First Event Date\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nLast Event Date Analysis\n\noptions(scipen=999)\nlast_event_analysis &lt;- season_table %&gt;%\n  group_by(GEOID, NAME) %&gt;%\n  do(tidy(lm(last_event ~ year_numerical, data = .)))\nlast_event_analysis = last_event_analysis %&gt;% filter(term != '(Intercept)')\n\n\nhist(last_event_analysis$p.value)\n\n\n\n\n\nMap\n\n# Merge with geometry data\ncounty_boundaris_catalog_all &lt;- merge(counties_geo,\n          last_event_analysis %&gt;% st_drop_geometry(),\n          by.x=\"GEOID\",\n          by.y=\"GEOID\",\n          all.x = TRUE,\n          all.y = TRUE,\n          suffix = c(\"\",\"_sp\")) %&gt;% st_as_sf() \n# area all map\nggplot() +\n  geom_sf(data = county_boundaris_catalog_all,\n            aes(fill = estimate), color = NA,\n            lwd = .1) + \n  scale_fill_distiller(palette = \"RdBu\", \n                       limits = c(-25, 25)\n                       ) +\n  geom_sf(data = states_geo, fill = NA, color = \"grey\", size = 0.01, alpha = 0.2) +\n  labs(fill = \"EHE Last Event Date\") +\n  theme_void() + \n  theme(legend.position = \"bottom\")\n\n\n\n#ggplot(result, aes(x = year_numerical, y = total_days, group = GEOID, color = GEOID)) +\n#  geom_line() +\n#  geom_point() +\n#  theme_minimal() +\n#  labs(title = \"Total Days Trend by County\",\n#       x = \"Year\",\n#       y = \"Total Days\",\n#       color = \"County (GEOID)\")"
  },
  {
    "objectID": "posts/observation/index.html",
    "href": "posts/observation/index.html",
    "title": "Interactive map — observation",
    "section": "",
    "text": "Extreme Heat/Cold Events Observation\nExtreme Heat/Cold Events observation summary from 2008 to 2022, including summary statics in average frequency, average absolute intensity, average impacted area to total area ratio and duration by event types.\n\n\n\n\n\n\n\nEHE: Extreme Heat Events\nECE: Extreme Cold Events"
  },
  {
    "objectID": "posts/trends/index.html",
    "href": "posts/trends/index.html",
    "title": "Interactive map — Trends",
    "section": "",
    "text": "Extreme Heat/Cold Events Frequency Trend Analysis"
  }
]
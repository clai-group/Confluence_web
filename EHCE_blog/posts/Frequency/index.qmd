---
title: "EHCE Frequency Trend Analysis"
author: "Jingya Cheng"
date: "2024-01-03"
categories: [code, analysis, trend]
---

# Extreme Heat/Cold Events Frequency Trend Analysis

```{r, include=FALSE}
library(readr)
library(viridis)
library(tidyverse)
library(sf)
library(gridExtra)
library(RColorBrewer)
library(pscl)
library(reshape2)
library(data.table)
library(broom)
library(DescTools)
library(MASS)
library(ggridges)
library(purrr)
library(leaflet)
```

### Loading the base spatail data set including Counties and States boundaires

```{r}
source_dir <- "./data/"
states_file_path <- file.path(source_dir,
                              "us49_states_geo_tigris.rds")
states_geo <- readRDS(states_file_path)[[1]]
counties_file_path <- file.path(source_dir,
                                "us49_counties_geo_tigris.rds")
counties_geo <- readRDS(counties_file_path)[[1]]
#plot(counties_geo[1])
```

### Loading the aggregate extreme events data set

```{r}
dat_path <- file.path(source_dir,
                      "Counties_compiled_admin_geo_ehe_ece_sf_2008_2022.rds")
file_size <- file.info(dat_path)$size
dat <- readRDS(dat_path)[[1]]
```

### Overall frequency analysis

#### Complete yearly aggregated counts

Complete the yearly frequency counts by assign 0 to that year when there's no extreme event records.

```{r}
dat_table = dat %>%  st_drop_geometry()
dat_table$total_area_sq_mile = dat_table$total_area/2590000

## Adding years with no event to the dataset 
lookup_table <- dat_table %>%
  dplyr::select(GEOID, NAME, STUSPS, STATE_NAME) %>%
  distinct() %>%
  filter(!is.na(NAME) & !is.na(STUSPS) & !is.na(STATE_NAME))

fill_na_with_lookup <- function(dat_table, lookup_table, column) {
  na_rows <- is.na(dat_table[[column]])
  lookup_values <- lookup_table[match(dat_table$GEOID[na_rows], lookup_table$GEOID), column]
  dat_table[[column]][na_rows] <- lookup_values
  return(dat_table)
}

year_range <- data.frame(year_numerical = 2008:2022)
unique_geoids <- unique(dat$GEOID)
year_geoid_combinations <- expand.grid(year_numerical = year_range$year_numerical, GEOID = unique_geoids)

event_count_all <- dat_table %>%
  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%
  summarize(event_count = n())

event_count_all <- merge(year_geoid_combinations, event_count_all, 
                         by = c("year_numerical", "GEOID"), all = TRUE)
event_count_all["event_count"] <- lapply(event_count_all["event_count"], function(x) ifelse(is.na(x), 0, x))
event_count_all <- fill_na_with_lookup(event_count_all, lookup_table, "NAME")
event_count_all <- fill_na_with_lookup(event_count_all, lookup_table, "STATE_NAME")

# Merge with average total area sq miles summary 
avg_total_area <- dat_table %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))
event_count_all = merge(event_count_all, avg_total_area, 
                         by = c("GEOID", "NAME", "STATE_NAME"), all = TRUE)

event_count_all = event_count_all %>% 
  group_by(GEOID, NAME, STATE_NAME) %>%
  mutate(mean_event_count = mean(event_count),
         sd = sd(event_count),
         outlier_upper = mean_event_count + 3*sd,
         outlier_lower = mean_event_count - 3*sd ) %>%
  mutate(event_count_outlier_rm = 
           ifelse((event_count>=outlier_lower&event_count<=outlier_upper), event_count, 0))
nrow(event_count_all %>% filter(event_count != event_count_outlier_rm))

```

### Season aggregation

```{r}
## Frequency summary by season
frequency_by_season = dat_table %>%
  mutate(season = ifelse((month(event_date) > 4 & month(event_date) < 10) | 
                       (month(event_date) == 4 & day(event_date) > 15) | 
                       (month(event_date) == 10 & day(event_date) < 15), "heat", "cold")) %>%
  group_by(GEOID, NAME, STATE_NAME, year_numerical,season) %>%
  summarize(event_count = n())

# Cold season
frequency_by_season_cold = frequency_by_season %>%
  filter(season == "cold")
frequency_by_season_cold <- merge(year_geoid_combinations, frequency_by_season_cold, 
                         by = c("year_numerical", "GEOID"), all = TRUE)
frequency_by_season_cold["event_count"] <- lapply(frequency_by_season_cold["event_count"], function(x) ifelse(is.na(x), 0, x))
frequency_by_season_cold["season"] <- lapply(frequency_by_season_cold["season"], function(x) ifelse(is.na(x), "cold", x))
frequency_by_season_cold <- fill_na_with_lookup(frequency_by_season_cold, lookup_table, "NAME")
frequency_by_season_cold <- fill_na_with_lookup(frequency_by_season_cold, lookup_table, "STATE_NAME")

# Heat season
frequency_by_season_heat = frequency_by_season %>%
  filter(season == "heat")
frequency_by_season_heat <- merge(year_geoid_combinations, frequency_by_season_heat, 
                         by = c("year_numerical", "GEOID"), all = TRUE)
frequency_by_season_heat["event_count"] <- lapply(frequency_by_season_heat["event_count"], function(x) ifelse(is.na(x), 0, x))
frequency_by_season_heat["season"] <- lapply(frequency_by_season_heat["season"], function(x) ifelse(is.na(x), "heat", x))
frequency_by_season_heat <- fill_na_with_lookup(frequency_by_season_heat, lookup_table, "NAME")
frequency_by_season_heat <- fill_na_with_lookup(frequency_by_season_heat, lookup_table, "STATE_NAME")

frequency_by_season = rbind(frequency_by_season_heat, frequency_by_season_cold)

#write.csv(frequency_by_season, "~/Desktop/frequency_season.csv")
```

#### Average counts by county

```{r, warning=FALSE}
## Yearly average counts per area
#avg_dat_by_year = event_count_all %>%
#  mutate(avg_counts = event_count/avg_total_area_sq_mile) %>% 
#  distinct()

#avg_dat_by_year %>% group_by(STATE_NAME) %>% 
#  ggplot(aes(x = avg_counts, y = STATE_NAME), data = .) +
#  stat_density_ridges(quantile_lines = TRUE, quantiles = 0.5)+ theme_minimal() + xlim(c(0,0.075))
  
# Overall average counts per area
avg_dat = dat_table %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(event_count = n(),
            avg_count_per_year = event_count/15,
            avg_total_area_100_sq_mile = mean(total_area_sq_mile)/100)%>%
  mutate(avg_counts = avg_count_per_year/avg_total_area_100_sq_mile) 


# map
avg_dat_map = avg_dat %>% 
  mutate(avg_counts_map = case_when(
    avg_counts < 0.1 ~ 0,
    avg_counts > 13 ~ 13,
    TRUE ~ avg_counts
  ))

#ggplot(avg_dat, aes(x = avg_counts)) + 
#  geom_histogram(aes(y = ..density..),
#                 colour = 1, fill = "white") +
#  geom_density(lwd = 1, colour = 4,
#               fill = 4, alpha = 0.25) +
#  geom_vline(aes(xintercept=mean(avg_counts, na.rm=T)),  
#               color="red", linetype="dashed", size=1) + xlim(c(0,1))

#avg_dat = avg_dat %>%
#  mutate(avg_counts_cat = case_when(
#    avg_counts < 0.14 ~ "<0.14",
#    avg_counts >=0.14 & avg_counts <= 0.26 ~ "0.14-0.26",
#    avg_counts >0.26 & avg_counts <= 1 ~ "0.26-1", 
#    TRUE ~ ">1"
#  )) %>%
#  mutate(avg_counts_cat = factor(avg_counts_cat, 
#                                        levels = c('<0.14', "0.14-0.26", '0.26-1',
#                                                   '>1')))

#avg_dat_ex = avg_dat %>% filter(STATE_NAME != "Virginia")
county_boundaries_catalog_all_counts <- merge(counties_geo,
          avg_dat %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 
#palette <- rev(brewer.pal(4, "RdYlBu"))
# Frequency all map with grey for non-significant p-values
p_count_all_map = ggplot() +
  geom_sf(data = county_boundaries_catalog_all_counts,
            aes(fill = avg_counts_map), color = NA,
            lwd = .1) + 
  scale_fill_gradientn(colors = c("white", "lightpink", "pink", 
                                  "mediumpurple", "darkmagenta"),
                       values = scales::rescale(c(0, 0.25, 0.5, 0.75, 1))) +
  geom_sf(data = states_geo, fill = NA, color = "grey", size = 0.5) +
  labs(fill = "Average Number of Extreme Events (2008-2022) per 100 square miles") +
  theme_void() + 
  theme(legend.position = "bottom")

#p_count_all_map
#png("~/Desktop/ehe_ece_data_integration/Frequency_maps/count_all_per_area.png",
#    height = 5, width = 7, res = 300, units = "in")
#print(p_count_all_map)
#dev.off()
```

### Regression Analaysis and Model Selection

#### NB regression

For each county, a poisson regression model is used to analyze the percentage changes by year.

```{r, message=FALSE, warning=FALSE}
#poisson_all_area_freq <- event_count_all %>%
#  group_by(GEOID, NAME, STATE_NAME) %>%
#  do(model = glm(event_count ~ year_numerical + 
#                    offset(log(avg_total_area_sq_mile)), family = poisson(), data = .))

#nb_all_area_freq <- event_count_all %>%
#  group_by(GEOID, NAME, STATE_NAME) %>%
#  do(model = MASS::glm.nb(event_count_outlier_rm ~ year_numerical + 
#                            offset(log(avg_total_area_sq_mile)), data = .))

# Calculating slopes, percentage changes, and evaluation metrics including goodness of fit and p-values
#slopes_all_area_adj <- nb_all_area_freq %>%
#  rowwise() %>%
#  mutate(
#    slope = coef(model)[["year_numerical"]],
#    percentage_change = (exp(slope) - 1) * 100,
#    p_value = summary(model)$coefficients["year_numerical","Pr(>|z|)"],
#    residual_deviance = deviance(model),
#    df_residual = df.residual(model),
#    deviance_ratio = residual_deviance / df_residual,  
#    dispersion = sum(residuals(model, type = "pearson")^2) / df_residual,  
#    aic = AIC(model),bic = BIC(model)
#  ) %>%
#  ungroup() %>%
#  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,
#         residual_deviance, df_residual, 
#         deviance_ratio, dispersion, aic,bic)

slopes_all <- event_count_all %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = MASS::glm.nb(event_count_outlier_rm ~ year_numerical + 
                            offset(log(avg_total_area_sq_mile)), data = .)
      coef_model = coef(model)["year_numerical"]
      percentage_change = (exp(coef_model) - 1) * 100
      p_values = summary(model)$coefficients["year_numerical", "Pr(>|z|)"]
      aic_value = AIC(model)
      bic_value = BIC(model)

      data.frame(coef = coef_model, percentage_change, p_value = p_values, 
                 AIC = aic_value, BIC = bic_value)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA, p_value = NA, 
                 AIC = NA, BIC = NA)
    })
  })

slopes_all_cut = slopes_all %>% filter(abs(percentage_change) < 45)
slopes_all_cut = slopes_all_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    TRUE ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))

#alabama = slopes_all_area_freq %>% filter(STATE_NAME == "Alabama")
#anova_result <- aov(slope ~ NAME, data = alabama)
#summary(anova_result)
#summary(anova_result)[[1]][["Pr(>F)"]][1]

#anova_results <- list()
#for (state_name in unique(slopes_all_area_freq$STATE_NAME)) {
#  state_data <- slopes_all_area_freq[slopes_all_area_freq$STATE_NAME == state_name, ]
#  if (length(unique(state_data$NAME)) > 1) {
#      anova_results[[state_name]] <- summary(aov(slope ~ NAME, data = state_data))
#  }
#}

```

#### ZINB + NB model (model selection)

```{r}
zeroinfl_all = event_count_all %>% group_by(GEOID, NAME, STATE_NAME) %>%
  filter((first(event_count_outlier_rm) == 0) | (sum(event_count_outlier_rm == 0) > 5)) %>%
  ungroup() 
slopes_all_zinb_area_adj <- zeroinfl_all %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = zeroinfl(event_count_outlier_rm ~ year_numerical | 1 + 
                            offset(log(avg_total_area_sq_mile)), data = .,
                       dist = "negbin")
      coef_model = coef(model)[2]
      percentage_change = (exp(coef_model) - 1) * 100

      data.frame(coef = coef_model, percentage_change)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA)
    })
  })

nb_all = event_count_all[!(event_count_all$GEOID %in% zeroinfl_all$GEOID),]
slope_all_nb = slopes_all[slopes_all$GEOID %in% nb_all$GEOID,]

slope_all_combine = rbind(slopes_all_zinb_area_adj, slope_all_nb)
slope_all_combinel_cut = slope_all_combine %>% filter(abs(percentage_change) < 45)
slope_all_combinel_cut = slope_all_combinel_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    percentage_change > 10 ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))

county_boundaris_all_catalog <- merge(counties_geo,
          slope_all_combinel_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 


p_combine_all = ggplot() +
  geom_sf(data = county_boundaris_all_catalog,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in EHCE Frequency (two models)") +
  theme_void() + 
  theme(legend.position = "bottom")
```

#### Model Selection

```{r, warning=FALSE}
NB_regression = event_count_all %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do(model = MASS::glm.nb(event_count ~ year_numerical + 
                            offset(log(avg_total_area_sq_mile)), data = .))

slopes_nb <- NB_regression %>%
  rowwise() %>%
  mutate(
    slope = coef(model)[["year_numerical"]],
    percentage_change = (exp(slope) - 1) * 100,
    p_value = summary(model)$coefficients["year_numerical","Pr(>|z|)"],
    residual_deviance = deviance(model),
    df_residual = df.residual(model),
    deviance_ratio = residual_deviance / df_residual,
    dispersion = sum(residuals(model, type = "pearson")^2) / df_residual,
    aic = AIC(model),
    bic = BIC(model)
  ) %>%
  ungroup() %>%
  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change, p_value,
         residual_deviance, df_residual, 
         deviance_ratio, dispersion, aic, bic)

model_comparison_table1 <- event_count_all %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(
    NB_Model_AIC = AIC(NB_regression$model[[1]]),
    Poisson_Model_AIC = AIC(poisson_all_area_freq$model[[1]]),
    Preferred_Model_AIC = ifelse(NB_Model_AIC < Poisson_Model_AIC, "Negative Binomial", "Poisson"),
    NB_Model_BIC = BIC(NB_regression$model[[1]]),
    Poisson_Model_BIC = BIC(poisson_all_area_freq$model[[1]]),
    Preferred_Model_BIC = ifelse(NB_Model_BIC < Poisson_Model_BIC, "Negative Binomial", "Poisson"),
    NB_Model_RD = NB_regression$model[[1]]$deviance,
    Poisson_Model_RD = poisson_all_area_freq$model[[1]]$deviance,
    Preferred_Model_RD = ifelse(NB_Model_RD < Poisson_Model_RD, "Negative Binomial", "Poisson")
  )
```

```{r}
#hist(slopes_all_area_freq$p_value)
#hist(slopes_all_area_freq$percentage_change)
#hist(slopes_all_area_freq$aic)
#hist(slopes_all_area_freq$pseudo_r_squared)
```

#### Map

```{r}
# Merge with geometry data
county_boundaries_catalog_all <- merge(counties_geo,
          slopes_all_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 

# Frequency all map with grey for non-significant p-values
#ggplot() +
#  geom_sf(data = county_boundaries_catalog_all,
#            aes(fill = percentage_change), color = NA,
#            lwd = .1) + 
#  scale_fill_distiller(palette = "RdBu", limits = c(-17,17)) +
#  geom_sf(data = states_geo, fill = NA, color = "grey", size = 0.5) +
#  labs(fill = "Frequency (Area adjusted)") +
#  theme_void() + 
#  theme(legend.position = "bottom")

#heat_colors <- c("<1%" = "lightblue", "1-5%" = "yellow", "5-10%" = "orange", ">10%" = "red")
palette <- rev(brewer.pal(8, "PuOr"))
p_perc_change_all = ggplot() +
  geom_sf(data = county_boundaries_catalog_all,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in Frequency (Area adjusted)") +
  theme_void() + 
  theme(legend.position = "bottom")
```

#### Interactive map

```{r}
pal <- colorNumeric(palette = magma(256, direction = -1), 
                    domain = county_boundaries_catalog_all$percentage_change)
pal_cat <- colorFactor(palette = rev(brewer.pal(8, "PuOr")), 
                   domain = county_boundaries_catalog_all$percentage_change_cat,
                   na.color=rgb(0,0,0,0))

county_boundaries_catalog_all_trans <- st_transform(county_boundaries_catalog_all, crs = 4326)
state_boundaris_catalog <- st_transform(states_geo, crs = 4326)
labels <- sprintf(
  "<strong>%s</strong><br/>%g ",
  county_boundaries_catalog_all$NAME, 
  county_boundaries_catalog_all$percentage_change) %>% 
  lapply(htmltools::HTML)
overall_interactive_plot <- leaflet(county_boundaries_catalog_all_trans) %>%
  addProviderTiles(providers$OpenStreetMap) %>% 
  addPolygons(data = state_boundaris_catalog,
              fillColor = NA,  
              weight = 2,
              color = "#000",  
              fillOpacity = 0) %>% 
  addPolygons(fillColor = ~pal_cat(percentage_change_cat),
              weight = 1,
              opacity = 1,
              color = "#888",
              dashArray = "3",
              fillOpacity = 0.7,
              highlightOptions = highlightOptions(
                weight = 3,
                color = "#555",
                dashArray = "",
                fillOpacity = 0.8,
                bringToFront = TRUE),
              label = labels,
              labelOptions = labelOptions(
                style = list("font-weight" = "normal", padding = "3px 8px"),
                textsize = "15px",
                direction = "auto")) %>%
  addLegend(pal = pal_cat, values = ~percentage_change_cat, opacity = 0.7, title = NULL,
  position = "bottomright",na.label = "") %>%
  addControl(
    html = "<strong>Percentage Change in EHCE Frequency</strong>",
    position = "bottomleft",
    className = "map-title"
)

overall_interactive_plot
```

### Extreme Heat Events

#### NB only Model

```{r, message=FALSE, warning=FALSE}
event_count_ehe <- dat_table %>%
  filter(event_type == "Extreme Heat Event") %>%
  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%
  summarize(event_count = n())

event_count_ehe <- merge(year_geoid_combinations, event_count_ehe, by = c("year_numerical", "GEOID"), all = TRUE)
event_count_ehe["event_count"] <- lapply(event_count_ehe["event_count"], function(x) ifelse(is.na(x), 0, x))
event_count_ehe <- fill_na_with_lookup(event_count_ehe, lookup_table, "NAME")
event_count_ehe <- fill_na_with_lookup(event_count_ehe, lookup_table, "STATE_NAME")

# Merge with average total area sq miles summary 
avg_total_area_ehe <- dat_table %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))
event_count_ehe = merge(event_count_ehe, avg_total_area_ehe, 
                         by = c("GEOID", "NAME", "STATE_NAME"), all = TRUE)

event_count_ehe = event_count_ehe %>% 
  group_by(GEOID, NAME, STATE_NAME) %>%
  mutate(mean_event_count = mean(event_count),
         sd = sd(event_count),
         outlier_upper = mean_event_count + 3*sd,
         outlier_lower = mean_event_count - 3*sd ) %>%
  mutate(event_count_outlier_rm = 
           ifelse((event_count>=outlier_lower&event_count<=outlier_upper), event_count, 0))
nrow(event_count_ehe %>% filter(event_count != event_count_outlier_rm))

# NB Regression
#poisson_ehe_area_adj <- event_count_ehe %>%
#  group_by(GEOID, NAME, STATE_NAME) %>%
#  do(model = MASS::glm.nb(event_count_outlier_rm ~ year_numerical + 
#                            offset(log(avg_total_area_sq_mile)), data = .))

#slopes_ehe_poi_area_adj <- poisson_ehe_area_adj %>%
#  rowwise() %>%
#  mutate(
#    slope = coef(model)[["year_numerical"]],
#    percentage_change = (exp(slope) - 1) * 100,
#    p_value = summary(model)$coefficients["year_numerical","Pr(>|z|)"],
#    residual_deviance = deviance(model),
#    df_residual = df.residual(model),
#    deviance_ratio = residual_deviance / df_residual,  
#    dispersion = sum(residuals(model, type = "pearson")^2) / df_residual,  
#    aic = AIC(model), bic = BIC(model)
#  ) %>%
#  ungroup() %>%
#  dplyr::select(GEOID, NAME, STATE_NAME, slope, percentage_change,p_value,
#         residual_deviance, df_residual, 
#         deviance_ratio, dispersion, aic,bic)

slopes_ehe_poi_area_adj <- event_count_ehe %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = MASS::glm.nb(event_count_outlier_rm ~ year_numerical + 
                            offset(log(avg_total_area_sq_mile)), data = .)
      coef_model = coef(model)["year_numerical"]
      percentage_change = (exp(coef_model) - 1) * 100
      p_values = summary(model)$coefficients["year_numerical", "Pr(>|z|)"]
      aic_value = AIC(model)
      bic_value = BIC(model)

      data.frame(coef = coef_model, percentage_change, p_value = p_values, 
                 AIC = aic_value, BIC = bic_value)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA, p_value = NA, 
                 AIC = NA, BIC = NA)
    })
  })
slopes_ehe_cut = slopes_ehe_poi_area_adj %>% filter(abs(percentage_change) < 45)
slopes_ehe_cut = slopes_ehe_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    TRUE ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))
```

```{r}
hist(slopes_ehe_poi_area_adj$p_value)
hist(slopes_ehe_poi_area_adj$percentage_change)
hist(slopes_ehe_poi_area_adj$aic)
```

#### ZINB + NB model (Model Selection)

```{r}
zeroinfl_ehe = event_count_ehe %>% group_by(GEOID, NAME, STATE_NAME) %>%
  filter((first(event_count_outlier_rm) == 0) | (sum(event_count_outlier_rm == 0) > 5)) %>%
  ungroup() 
slopes_ehe_zinb_area_adj <- zeroinfl_ehe %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = zeroinfl(event_count_outlier_rm ~ year_numerical | 1 + 
                            offset(log(avg_total_area_sq_mile)), data = .,
                       dist = "negbin")
      coef_model = coef(model)[2]
      percentage_change = (exp(coef_model) - 1) * 100

      data.frame(coef = coef_model, percentage_change)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA)
    })
  })

nb_ehe = event_count_ehe[!(event_count_ehe$GEOID %in% zeroinfl_ehe$GEOID),]
slope_ehe_nb = slopes_ehe_poi_area_adj[slopes_ehe_poi_area_adj$GEOID %in% nb_ehe$GEOID,]

slope_ehe_combine = rbind(slopes_ehe_zinb_area_adj, slope_ehe_nb)
slope_ehe_combine_cut = slope_ehe_combine %>% filter(abs(percentage_change) < 45)
slope_ehe_combine_cut = slope_ehe_combine_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    percentage_change > 10 ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))

county_boundaris_ece_catalog <- merge(counties_geo,
          slope_ehe_combine_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 


p_combine_ehe = ggplot() +
  geom_sf(data = county_boundaris_ece_catalog,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in Frequency EHE (two models)") +
  theme_void() + 
  theme(legend.position = "bottom")

p_combine_ehe
```

#### Average Counts by County

```{r}
avg_counts_county_ehe = dat_table %>%
  filter(event_type == "Extreme Heat Event") %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(event_count = n(),
            avg_count_per_year = event_count/15,
            avg_total_area_100_sq_mile = mean(total_area_sq_mile)/100)%>%
  mutate(avg_counts = avg_count_per_year/avg_total_area_100_sq_mile) 

# map
avg_dat_map_ehe = avg_counts_county_ehe %>% 
  mutate(avg_counts_map = case_when(
    avg_counts < 0.1 ~ 0,
    avg_counts > 13 ~ 13,
    TRUE ~ avg_counts
  ))

#avg_dat_ex_ehe = avg_counts_county_ehe %>% filter(STATE_NAME != "Virginia")
county_boundaries_catalog_ehe_counts <- merge(counties_geo,
          avg_dat_map_ehe %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 

# Frequency all map with grey for non-significant p-values
p_ehe_count_map = ggplot() +
  geom_sf(data = county_boundaries_catalog_ehe_counts,
            aes(fill = avg_counts_map), color = NA,
            lwd = .1) + 
  scale_fill_gradientn(colors = c("white", "yellow", "orange", "red", "darkred"),
                       values = scales::rescale(c(0, 0.25, 0.5, 0.75, 1))) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Average Number of Extreme Heat Events per 100 Square Miles (2008-2022)") +
  theme_void() + 
  theme(legend.position = "bottom")

#p_ehe_count_map
#png("~/Desktop/count_ehe_per_area.png",
#    height = 5, width = 7, res = 300, units = "in")
#print(p_ehe_count_map)
#dev.off()
```

#### Map

```{r}
# Merge with geometry data
county_boundaris_ehe_catalog <- merge(counties_geo,
          slopes_ehe_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 

# Frequency EHE map
#ggplot() +
#  geom_sf(data = county_boundaris_ehe_catalog,
#            aes(fill = percentage_change), color = NA,
#            lwd = .1) + 
#  scale_fill_distiller(palette = "RdBu", limit = c(-42.5, 42.5)) +
#  geom_sf(data = states_geo, fill = NA, color = "grey", size = 0.1) +
#  labs(fill = "Frequency EHE (Adjusted by Area)") +
#  theme_void() + 
#  theme(legend.position = "bottom")

#heat_colors <- c("<1%" = "lightblue", "1-5%" = "yellow", "5-10%" = "orange", ">10%" = "red")
#palette_ehe <- rev(brewer.pal(8, "RdBu"))
p_perc_change_ehe = ggplot() +
  geom_sf(data = county_boundaris_ehe_catalog,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in Frequency EHE (Area adjusted)") +
  theme_void() + 
  theme(legend.position = "bottom")

#p_perc_change_ehe
#png("~/Desktop/ehe_ece_data_integration/Frequency_maps/perc_change_ehe.png",
#    height = 5, width = 7, res = 300, units = "in")
#print(p_perc_change_ehe)
#dev.off()
```

#### Interactive map

```{r}
pal_cat <- colorFactor(palette = rev(brewer.pal(8, "PuOr")), 
                   domain = county_boundaris_ehe_catalog$percentage_change_cat)

county_boundaries_catalog_ehe_trans <- st_transform(county_boundaris_ehe_catalog, crs = 4326)
state_boundaris_catalog <- st_transform(states_geo, crs = 4326)

labels_ehe <- sprintf(
  "<strong>%s</strong><br/>%g ",
  county_boundaris_ehe_catalog$NAME, 
  county_boundaris_ehe_catalog$percentage_change) %>% 
  lapply(htmltools::HTML)
total_ehe_interactive_plot <- leaflet(county_boundaries_catalog_ehe_trans) %>%
  addProviderTiles(providers$OpenStreetMap) %>% 
  addPolygons(data = state_boundaris_catalog,
              fillColor = NA,  
              weight = 2,
              color = "#000",  
              fillOpacity = 0) %>% 
  addPolygons(fillColor = ~pal_cat(percentage_change_cat),
              weight = 1,
              opacity = 1,
              color = "#888",
              dashArray = "3",
              fillOpacity = 0.7,
              highlightOptions = highlightOptions(
                weight = 3,
                color = "#555",
                dashArray = "",
                fillOpacity = 0.8,
                bringToFront = TRUE),
              label = labels_ehe,
              labelOptions = labelOptions(
                style = list("font-weight" = "normal", padding = "3px 8px"),
                textsize = "15px",
                direction = "auto")) %>%
  addLegend(pal = pal_cat, values = ~percentage_change_cat, opacity = 0.7, title = NULL,
  position = "bottomright",na.label = "") %>%
  addControl(
    html = "<strong>Percentage Change in EHE Frequency</strong>",
    position = "bottomleft",
    className = "map-title"
)
total_ehe_interactive_plot
```

### Extreme Cold Events

#### NB model only

```{r, message=FALSE, warning=FALSE}
event_count_ece <- dat_table %>%
  filter(event_type == "Extreme Cold Event") %>%
  group_by(GEOID, NAME, STATE_NAME, year_numerical) %>%
  summarize(event_count = n())

event_count_ece <- merge(year_geoid_combinations, event_count_ece, by = c("year_numerical", "GEOID"), all = TRUE)
event_count_ece["event_count"] <- lapply(event_count_ece["event_count"], function(x) ifelse(is.na(x), 0, x))
event_count_ece <- fill_na_with_lookup(event_count_ece, lookup_table, "NAME")
event_count_ece <- fill_na_with_lookup(event_count_ece, lookup_table, "STATE_NAME")

# Merge with average total area sq miles summary 
avg_total_area_ece <- dat_table %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(avg_total_area_sq_mile = mean(total_area_sq_mile))
event_count_ece = merge(event_count_ece, avg_total_area_ece, 
                         by = c("GEOID", "NAME", "STATE_NAME"), all = TRUE)

event_count_ece = event_count_ece %>% 
  group_by(GEOID, NAME, STATE_NAME) %>%
  mutate(mean_event_count = mean(event_count),
         sd = sd(event_count),
         outlier_upper = mean_event_count + 3*sd,
         outlier_lower = mean_event_count - 3*sd ) %>%
  mutate(event_count_outlier_rm = 
           ifelse((event_count>=outlier_lower&event_count<=outlier_upper), event_count, 0))

nrow(event_count_ece %>% filter(event_count != event_count_outlier_rm))

# NB Regression
slopes_ece_poi_area_adj <- event_count_ece %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = MASS::glm.nb(event_count_outlier_rm ~ year_numerical + 
                            offset(log(avg_total_area_sq_mile)), data = .)
      coef_model = coef(model)["year_numerical"]
      percentage_change = (exp(coef_model) - 1) * 100
      p_values = summary(model)$coefficients["year_numerical", "Pr(>|z|)"]
      aic_value = AIC(model)
      bic_value = BIC(model)

      data.frame(coef = coef_model, percentage_change, p_value = p_values, 
                 AIC = aic_value, BIC = bic_value)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA, p_value = NA, 
                 AIC = NA, BIC = NA)
    })
  })


#poisson_ece_area_adj <- event_count_ece %>%
#  group_by(GEOID, NAME, STATE_NAME) %>%
#  do(model = glm(event_count ~ year_numerical + 
#                   offset(log(avg_total_area_sq_mile)), family = quasipoisson, data = .))

slopes_ece_cut = slopes_ece_poi_area_adj %>% filter(abs(percentage_change) < 45)
slopes_ece_cut = slopes_ece_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    percentage_change > 10 ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))
```

#### ZINB + NB model

```{r, warning = F}
zeroinfl_ece = event_count_ece %>% group_by(GEOID, NAME, STATE_NAME) %>%
  filter((first(event_count_outlier_rm) == 0) | (sum(event_count_outlier_rm == 0) > 5)) %>%
  ungroup() 
slopes_ece_zinb_area_adj <- zeroinfl_ece %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  do({
    # Fit the Negative Binomial model
    tryCatch({
      model = zeroinfl(event_count_outlier_rm ~ year_numerical | 1 + 
                            offset(log(avg_total_area_sq_mile)), data = .,
                       dist = "negbin")
      coef_model = coef(model)[2]
      percentage_change = (exp(coef_model) - 1) * 100

      data.frame(coef = coef_model, percentage_change)
    }, error = function(e) {
      # Return NA in case of an error
      data.frame(coef = NA, percentage_change = NA)
    })
  })

nb_ece = event_count_ece[!(event_count_ece$GEOID %in% zeroinfl_ece$GEOID),]
slope_ece_nb = slopes_ece_poi_area_adj[slopes_ece_poi_area_adj$GEOID %in% nb_ece$GEOID,]

slope_ece_combine = rbind(slopes_ece_zinb_area_adj, slope_ece_nb)
slope_ece_combine_cut = slope_ece_combine %>% filter(abs(percentage_change) < 45)
slope_ece_combine_cut = slope_ece_combine_cut %>%
  mutate(percentage_change_cat = case_when(
    percentage_change < -10 ~ "<-10%",
    percentage_change >=-10 & percentage_change<= -5 ~ "-10 - -5%",
    percentage_change >-5 & percentage_change<= -1 ~ "-5 - -1%",
    percentage_change >-1 & percentage_change<= 0 ~ "-1-0%",
    percentage_change >0 & percentage_change<= 1 ~ "0-1%",
    percentage_change >1 & percentage_change <= 5 ~ "1-5%",
    percentage_change >5 & percentage_change <= 10 ~ "5-10%", 
    percentage_change > 10 ~ ">10%"
  )) %>%
  mutate(percentage_change_cat = factor(percentage_change_cat, 
                                        levels = c("<-10%","-10 - -5%","-5 - -1%",
                                                   "-1-0%","0-1%",
                                                   "1-5%", "5-10%", ">10%")))

county_boundaris_ece_catalog <- merge(counties_geo,
          slope_ece_combine_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 


p_combine_ece = ggplot() +
  geom_sf(data = county_boundaris_ece_catalog,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in Frequency ECE (two models)") +
  theme_void() + 
  theme(legend.position = "bottom")

p_combine_ece
```

```{r}
#hist(slopes_ece_poi$p_value)
#hist(slopes_ece_poi$percentage_change)
#hist(slopes_ece_poi$aic)
```

#### Average counts by county

```{r}
avg_counts_county_ece = dat_table %>%
  filter(event_type == "Extreme Cold Event") %>%
  group_by(GEOID, NAME, STATE_NAME) %>%
  summarize(event_count = n(),
            avg_count_per_year = event_count/15,
            avg_total_area_100_sq_mile = mean(total_area_sq_mile)/100)%>%
  mutate(avg_counts = avg_count_per_year/avg_total_area_100_sq_mile) 

# map
avg_dat_map_ece = avg_counts_county_ece %>% 
  mutate(avg_counts_map = case_when(
    avg_counts < 0.1 ~ 0,
    avg_counts > 13 ~ 13,
    TRUE ~ avg_counts
  ))
county_boundaries_catalog_ece_counts <- merge(counties_geo,
          avg_dat_map_ece %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 

# Frequency all map with grey for non-significant p-values
p_ece_count_map = ggplot() +
  geom_sf(data = county_boundaries_catalog_ece_counts,
            aes(fill = avg_counts_map), color = NA,
            lwd = .1) + 
  scale_fill_gradientn(colors = c("white", "lightblue", "dodgerblue", "blue", "darkblue"),
                       values = scales::rescale(c(0, 0.25, 0.5, 0.75, 1))) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Average Number of Extreme Cold Events per 100 Square Miles  (2008-2022)") +
  theme_void() + 
  theme(legend.position = "bottom")

#p_ece_count_map
#png("~/Desktop/count_ece_per_area.png",
#    height = 5, width = 7, res = 300, units = "in")
#print(p_ece_count_map)
#dev.off()
```

#### Map

```{r}
# Merge with geometry data
county_boundaris_ece_catalog <- merge(counties_geo,
          slopes_ece_cut %>% st_drop_geometry(),
          by.x="GEOID",
          by.y="GEOID",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf()      

# Frequency ECE map
#ggplot() +
#  geom_sf(data = county_boundaris_ece_catalog,
#            aes(fill = percentage_change), color = NA,
#            lwd = .1) + 
#  scale_fill_distiller(palette = "RdBu", limit = c(-27, 27)) +
#  geom_sf(data = states_geo, fill = NA, color = "grey", size = 0.5) +
#  labs(fill = "Frequency ECE (Adjusted by area)") +
#  theme_void() + 
#  theme(legend.position = "bottom")

#heat_colors <- c("<1%" = "lightblue", "1-5%" = "yellow", "5-10%" = "orange", ">10%" = "red")
#palette_ece <- brewer.pal(8, "RdBu")
p_perc_change_ece = ggplot() +
  geom_sf(data = county_boundaris_ece_catalog,
            aes(fill = percentage_change_cat), color = NA,
            lwd = .1) + 
  scale_fill_manual(values = palette, na.translate = F) +
  geom_sf(data = states_geo, fill = NA, color = "black", size = 0.1) +
  labs(fill = "Percentage Change in Frequency ECE (Area adjusted)") +
  theme_void() + 
  theme(legend.position = "bottom")

p_perc_change_ece
png("~/Desktop/ehe_ece_data_integration/Frequency_maps/perc_change_ece.png",
    height = 5, width = 7, res = 300, units = "in")
print(p_perc_change_ece)
dev.off()
```

#### Interactive map

```{r}
pal_cat <- colorFactor(palette = rev(brewer.pal(8, "PuOr")), 
                   domain = county_boundaris_ece_catalog$percentage_change_cat)

county_boundaries_catalog_ece_trans <- st_transform(county_boundaris_ece_catalog, crs = 4326)
state_boundaris_catalog <- st_transform(states_geo, crs = 4326)

labels_ece <- sprintf(
  "<strong>%s</strong><br/>%g ",
  county_boundaris_ece_catalog$NAME, 
  county_boundaris_ece_catalog$percentage_change) %>% 
  lapply(htmltools::HTML)
total_ece_interactive_plot <- leaflet(county_boundaries_catalog_ece_trans) %>%
  addProviderTiles(providers$OpenStreetMap) %>% 
  addPolygons(data = state_boundaris_catalog,
              fillColor = NA,  
              weight = 2,
              color = "#000",  
              fillOpacity = 0) %>% 
  addPolygons(fillColor = ~pal_cat(percentage_change_cat),
              weight = 1,
              opacity = 1,
              color = "#888",
              dashArray = "3",
              fillOpacity = 0.7,
              highlightOptions = highlightOptions(
                weight = 3,
                color = "#555",
                dashArray = "",
                fillOpacity = 0.8,
                bringToFront = TRUE),
              label = labels_ece,
              labelOptions = labelOptions(
                style = list("font-weight" = "normal", padding = "3px 8px"),
                textsize = "15px",
                direction = "auto")) %>%
  addLegend(pal = pal_cat, values = ~percentage_change_cat, opacity = 0.7, title = NULL,
  position = "bottomright",na.label = "") %>%
  addControl(
    html = "<strong>Percentage Change in ECE Frequency</strong>",
    position = "bottomleft",
    className = "map-title"
)
total_ece_interactive_plot
```

### State Level Analysis

```{r}
state_ehe_dat = event_count_ehe %>% 
  dplyr::select(year_numerical, STATE_NAME, event_count) 

poi_state_ehe <- state_ehe_dat %>%
  group_by(STATE_NAME) %>%
  do(model = glm(event_count ~ year_numerical, family = poisson(), data = .))

slopes_state_ehe <- poi_state_ehe %>%
  rowwise() %>%
  mutate(
    slope = coef(model)[["year_numerical"]],
    percentage_change = (exp(slope) - 1) * 100,
    p_value = summary(model)$coefficients["year_numerical","Pr(>|z|)"],
    residual_deviance = deviance(model),
    df_residual = df.residual(model),
    deviance_ratio = residual_deviance / df_residual,  # Ratio of residual deviance to degrees of freedom
    dispersion = sum(residuals(model, type = "pearson")^2) / df_residual,  # Dispersion parameter
    aic = AIC(model)
  ) %>%
  ungroup() %>%
  dplyr::select(STATE_NAME, slope, percentage_change,p_value,
         residual_deviance, df_residual, 
         deviance_ratio, dispersion, aic)

```

#### Map

```{r}
# Merge with geometry data
state_boundaris_ehe_catalog <- merge(states_geo,
          slopes_state_ehe %>% st_drop_geometry(),
          by.x="STATE_NAME",
          by.y="STATE_NAME",
          all.x = TRUE,
          all.y = TRUE,
          suffix = c("","_sp")) %>% st_as_sf() 
# Area ECE map
ggplot() +
  geom_sf(data = state_boundaris_ehe_catalog,
            aes(fill = percentage_change), color = NA,
            lwd = .1) + 
  scale_fill_distiller(palette = "RdBu", 
                       limits = c(-10.7, 10.7)
                       ) +
  geom_sf(data = states_geo, fill = NA, color = "grey", size = 0.5) +
  labs(fill = "State Frequency EHE") +
  theme_void() + 
  theme(legend.position = "bottom")
```
